---
    title: "The current problem with P2P protocols"
    type: "multiple-choice"
---

Peer-to-peer (P2P) networks were envisioned from the very conception of the internet as a way to create resilient networks that would function even if peers disconnected from the network due to major natural or human disasters, allowing people to continue to communicate.

P2P networks can be used for a variety of use cases, from video calls (eg Skype) to file sharing (eg IPFS, Gnutella, KaZaA, eMule, and BitTorrent).

## Reinventing the wheel

One of the main challenges that all apps with P2P connections have to solve is discoverability: how can two or more peers find each other and share information? In the past, each P2P app has tackled this problem (among many others) and implemented their own solutions with different ideas and approaches customized to their individual use case.

IPFS searched for inspiration in current and past networking applications and research to try and improve its P2P system. There were plenty of scientific papers from the world of academia that provided ideas on how to solve some of these issues, but while research yielded preliminary results, it lacked code implementations that could be used and adapted.

Code implementations of existing P2P systems were really hard to find, and where they did exist, they were often hard to re-use or re-purpose due to:

- Poor or non-existent documentation
- Restrictive licensing or no license to be found
- Very old code with the last update more than a decade ago
- No point of contact (no maintainer available to reach)
- Closed source (private) code
- Deprecated products
- No specifications provided
- No friendly API exposed
- Implementations too tightly coupled with a specific use case
- Not upgradable with future protocols

So in the end, every time P2P protocols were needed, developers would solve the same challenges again and again from scratch because the P2P protocols already embedded in software packages weren't extractable and reusable.

One would think that this was a problem of the past.
The open-source community has evolved over the years and built a robust ecosystem that provides thousands of open-source software packages that include a thorough battery of test suites, good documentation, and friendly APIs. But unfortunately, no good P2P protocol implementation had appeared that solved all of the presented issues across a variety of use cases.

Historically, companies that produced products like Skype or BitTorrent created their own protocols to support them. Those protocols made a lot of assumptions about the environments they'd run in and the needs they'd meet, making them incredibly hard to upgrade or adapt to new environments.

## The solution

Of course the answer to all of these problems was a shiny new protocol that solved all of these problems once and for all! Well... not exactly.

<div class="flex justify-center flex-column items-center">
    <img src="/tutorial-assets/T0009L02-standards-comic-xkcd.png" alt="Cartoon from xkcc.com showing how standards profilerate, with developers proposing a new universal standard to cover all use cases and ending up with just one more competing standard">
    <a class="tc f6 ph4 w-50 mt2 no-underline grey" href="https://xkcd.com/927/" target="_blank">xkcd.com/927</a>
</div>

There had to be a better way.
Seeing that the main issue was interoperability, the IPFS team envisioned a better way to integrate all current solutions and provide a platform that facilitated innovation. A new modular system that would enable future solutions to be seamlessly integrated into the networking stack.

Enter libp2p.
